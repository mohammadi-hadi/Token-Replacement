Model,Language,Domain,Accuracy,Precision,Recall,F1
XGBoost,en,news,0.902,0.944,0.85,0.895
BERT-base,en,news,0.976,1.0,0.95,0.974
DistilBERT,en,news,0.951,0.909,1.0,0.952
XLM-RoBERTa,en,news,0.488,0.488,1.0,0.656
Ensemble,en,news,0.951,1.0,0.9,0.947
XGBoost,en,reviews,0.513,0.565,0.591,0.578
BERT-base,en,reviews,0.513,0.56,0.636,0.596
DistilBERT,en,reviews,0.718,0.72,0.818,0.766
XLM-RoBERTa,en,reviews,0.564,0.564,1.0,0.721
Ensemble,en,reviews,0.667,0.714,0.682,0.698
XGBoost,en,twitter,0.976,0.95,1.0,0.974
BERT-base,en,twitter,0.929,0.864,1.0,0.927
DistilBERT,en,twitter,0.929,0.864,1.0,0.927
XLM-RoBERTa,en,twitter,0.595,0.528,1.0,0.691
Ensemble,en,twitter,0.929,0.864,1.0,0.927
XGBoost,nl,news,0.897,0.905,0.905,0.905
BERT-base,nl,news,0.692,0.8,0.571,0.667
DistilBERT,nl,news,0.692,0.737,0.667,0.7
XLM-RoBERTa,nl,news,0.538,0.538,1.0,0.7
Ensemble,nl,news,1.0,1.0,1.0,1.0
XGBoost,nl,reviews,0.643,0.565,0.722,0.634
BERT-base,nl,reviews,0.5,0.4,0.333,0.364
DistilBERT,nl,reviews,0.452,0.407,0.611,0.489
XLM-RoBERTa,nl,reviews,0.429,0.429,1.0,0.6
Ensemble,nl,reviews,0.595,0.533,0.444,0.485
XGBoost,nl,twitter,0.919,0.947,0.9,0.923
BERT-base,nl,twitter,0.919,0.947,0.9,0.923
DistilBERT,nl,twitter,0.946,0.95,0.95,0.95
XLM-RoBERTa,nl,twitter,0.622,0.6,0.9,0.72
Ensemble,nl,twitter,0.865,0.895,0.85,0.872
